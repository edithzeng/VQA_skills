{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using CNTK backend\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/cntk_backend.py:25: UserWarning: CNTK backend warning: GPU is not detected. CNTK's CPU version is not fully optimized,please run with GPU to get better performance.\n",
      "  'CNTK backend warning: GPU is not detected. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/edithzeng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/edithzeng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=10)\n",
    "import nltk \n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# for LSTM (keras with tf backend)\n",
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "os.environ['KERAS_BACKEND']='cntk'\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.initializers import he_normal\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.callbacks import History, CSVLogger\n",
    "from keras.utils import to_categorical\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "MAX_DOC_LEN = 40\n",
    "VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizwiz_features_train_color = pd.read_csv('azure_features_images/data/vizwiz_train_color_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "vizwiz_features_train_text = pd.read_csv('azure_features_images/data/vizwiz_train_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vizwiz_features_val_color = pd.read_csv('azure_features_images/data/vizwiz_val_color_recognition.csv',\n",
    "                                  delimiter=';', engine='python',\n",
    "                                  dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                  quotechar='\"', error_bad_lines=False)\n",
    "vizwiz_features_val_text = pd.read_csv('azure_features_images/data/vizwiz_val_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vqa_features_train_color = pd.read_csv('azure_features_images/data/vqa_train_color_recognition.csv',\n",
    "                                 delimiter=';', engine='python', \n",
    "                                 dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                 quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_train_text = pd.read_csv('azure_features_images/data/vqa_train_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_val_color = pd.read_csv('azure_features_images/data/vqa_val_color_recognition.csv',\n",
    "                               delimiter=';', engine='python',\n",
    "                               dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                               quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_val_text = pd.read_csv('azure_features_images/data/vqa_val_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vizwiz_targets_train = pd.read_csv('../vizwiz_skill_typ_train.csv', dtype={'QID':str},\n",
    "                                   delimiter=',', quotechar='\"',\n",
    "                                   engine='python', error_bad_lines=False)\n",
    "vizwiz_targets_val = pd.read_csv('../vizwiz_skill_typ_val.csv', dtype={'QID':str},\n",
    "                                 delimiter=',', quotechar='\"', engine='python', error_bad_lines=False)\n",
    "vqa_targets_train = pd.read_csv('../vqa_skill_typ_train.csv', dtype={'QID':str},\n",
    "                               engine='python', quotechar='\"', error_bad_lines=False)\n",
    "vqa_targets_val = pd.read_csv('../vqa_skill_typ_val.csv', dtype={'QID':str},\n",
    "                               engine='python', quotechar='\"', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_feature_target(feature_df_text, feature_df_color, target_df):\n",
    "    feature_text = copy.deepcopy(feature_df_text)\n",
    "    feature_color = copy.deepcopy(feature_df_color)\n",
    "    target = copy.deepcopy(target_df)\n",
    "    # text features \n",
    "    feature_text.rename({'qid': 'QID'}, axis=1, inplace=True)\n",
    "    feature_text.set_index('QID', inplace=True)\n",
    "    # color features\n",
    "    feature_color.rename({'qid': 'QID'}, axis=1, inplace=True)\n",
    "    feature_color.set_index('QID', inplace=True)\n",
    "    # join features\n",
    "    features = feature_text.join(feature_color[['descriptions','tags','dominant_colors']],\n",
    "                                 on='QID',\n",
    "                                 how='outer')\n",
    "    # join features with target\n",
    "    target = target[['QID', 'IMG', 'QSN', 'TXT', 'OBJ', 'COL', 'CNT', 'OTH']]\n",
    "    target.set_index('QID', inplace=True)\n",
    "    target = target.astype(dtype=str)\n",
    "    df = target.join(features, on='QID', how='inner')\n",
    "    df['descriptions'].astype(list)\n",
    "    return df\n",
    "\n",
    "def lem(s):\n",
    "    arr = s.split(\" \")\n",
    "    lem = WordNetLemmatizer()\n",
    "    op = \"\"\n",
    "    for w in arr:\n",
    "        word = lem.lemmatize(w) + ' '\n",
    "        op += word\n",
    "    return op\n",
    "\n",
    "def preprocess_text(feature_columns):\n",
    "    \"\"\" output an nparray with single document per data point \"\"\"\n",
    "    ip = copy.deepcopy(feature_columns).values\n",
    "    op = []\n",
    "    for i in range(ip.shape[0]):\n",
    "        doc      =  \"\"\n",
    "        for j in range(ip.shape[1]):\n",
    "            # clean up chars\n",
    "            s    =  str(ip[i][j])\n",
    "            s    =  s.translate({ord(c): \"\" for c in \"!@#$%^&*()[]{};:,./<>?\\|`~-=_+'\"}).lower() + \" \"\n",
    "            if j == 1:             # clean descriptions\n",
    "                s = re.sub(r'confidence\\s+\\d+', '', s)\n",
    "                s = re.sub(r'text', '', s)\n",
    "            # lexicon normalize\n",
    "            s    = lem(s)\n",
    "            doc  += (s.strip())\n",
    "        op.append(doc)\n",
    "    op = np.asarray(op)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14257, 13) (3230, 13) 17487\n",
      "(2247, 13) (513, 13) 2760\n",
      "Training: (17487, 13)\n",
      "Validation: (2760, 13)\n"
     ]
    }
   ],
   "source": [
    "vizwiz_train   = join_feature_target(vizwiz_features_train_text, \n",
    "                                   vizwiz_features_train_color, \n",
    "                                   vizwiz_targets_train)\n",
    "vizwiz_val     = join_feature_target(vizwiz_features_val_text, \n",
    "                                 vizwiz_features_val_color, \n",
    "                                 vizwiz_targets_val)\n",
    "vqa_train      = join_feature_target(vqa_features_train_text, \n",
    "                                   vqa_features_train_color, \n",
    "                                   vqa_targets_train)\n",
    "vqa_val        = join_feature_target(vizwiz_features_val_text, \n",
    "                                 vqa_features_val_color, \n",
    "                                 vqa_targets_val)\n",
    "print(vizwiz_train.shape, vqa_train.shape, vizwiz_train.shape[0] + vqa_train.shape[0])\n",
    "print(vizwiz_val.shape, vqa_val.shape, vizwiz_val.shape[0] + vqa_val.shape[0])\n",
    "\n",
    "# create X and Y\n",
    "\n",
    "train = pd.concat([vizwiz_train, vqa_train], axis=0)\n",
    "val   = pd.concat([vizwiz_val, vqa_val], axis=0)\n",
    "print(\"Training: {}\\nValidation: {}\".format(train.shape, val.shape))\n",
    "\n",
    "features_train = preprocess_text(train[['QSN','descriptions', 'tags', 'dominant_colors', \n",
    "                                        'handwritten_text', 'ocr_text']])\n",
    "txt_train      = train['TXT'].values\n",
    "col_train      = train['COL'].values\n",
    "cnt_train      = train['CNT'].values\n",
    "\n",
    "features_val   = preprocess_text(val[['QSN', 'descriptions', 'tags', 'dominant_colors',\n",
    "                                      'handwritten_text', 'ocr_text']])\n",
    "txt_val        = val['TXT'].values.astype('float32')\n",
    "col_val        = val['COL'].values.astype('float32')\n",
    "cnt_val        = val['CNT'].values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples each class - Vizwiz - train\n",
      "Text recognition [9119. 8368.]\n",
      "Color recognition [10926.  6561.]\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "tok        = Tokenizer(num_words=VOCAB_SIZE, \n",
    "                       filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                       lower=True,\n",
    "                       split=\" \")\n",
    "tok.fit_on_texts(features_train)\n",
    "\n",
    "# create sequences & pad\n",
    "train_seq  = tok.texts_to_sequences(features_train)\n",
    "train_seq  = sequence.pad_sequences(train_seq, maxlen=MAX_DOC_LEN)\n",
    "val_seq    = tok.texts_to_sequences(features_val)\n",
    "val_seq    = sequence.pad_sequences(val_seq, maxlen=MAX_DOC_LEN)\n",
    "\n",
    "# check class distribution\n",
    "text_recognition_labels = to_categorical(np.asarray(txt_train)).astype('float32')\n",
    "color_recognition_labels = to_categorical(np.asarray(col_train)).astype('float32')\n",
    "print('Number of samples each class - Vizwiz - train')\n",
    "print('Text recognition', text_recognition_labels.sum(axis=0))\n",
    "print('Color recognition', color_recognition_labels.sum(axis=0))\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-28 14:41:03,498 : INFO : collecting all words and their counts\n",
      "2019-02-28 14:41:03,499 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-02-28 14:41:03,562 : INFO : PROGRESS: at sentence #10000, processed 347442 words, keeping 31941 word types\n",
      "2019-02-28 14:41:03,612 : INFO : collected 44967 word types from a corpus of 609446 raw words and 17487 sentences\n",
      "2019-02-28 14:41:03,613 : INFO : Loading a fresh vocabulary\n",
      "2019-02-28 14:41:03,649 : INFO : effective_min_count=6 retains 4665 unique words (10% of original 44967, drops 40302)\n",
      "2019-02-28 14:41:03,650 : INFO : effective_min_count=6 leaves 553935 word corpus (90% of original 609446, drops 55511)\n",
      "2019-02-28 14:41:03,662 : INFO : deleting the raw counts dictionary of 44967 items\n",
      "2019-02-28 14:41:03,665 : INFO : sample=0.001 downsamples 65 most-common words\n",
      "2019-02-28 14:41:03,667 : INFO : downsampling leaves estimated 389589 word corpus (70.3% of prior 553935)\n",
      "2019-02-28 14:41:03,685 : INFO : estimated required memory for 4665 words and 100 dimensions: 6064500 bytes\n",
      "2019-02-28 14:41:03,685 : INFO : resetting layer weights\n",
      "2019-02-28 14:41:03,739 : INFO : training model with 6 workers on 4665 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-28 14:41:04,309 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-28 14:41:04,317 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-28 14:41:04,319 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-28 14:41:04,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-28 14:41:04,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-28 14:41:04,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-28 14:41:04,351 : INFO : EPOCH - 1 : training on 609446 raw words (389227 effective words) took 0.6s, 642339 effective words/s\n",
      "2019-02-28 14:41:05,002 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-28 14:41:05,012 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-28 14:41:05,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-28 14:41:05,013 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-28 14:41:05,016 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-28 14:41:05,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-28 14:41:05,017 : INFO : EPOCH - 2 : training on 609446 raw words (389525 effective words) took 0.7s, 592898 effective words/s\n",
      "2019-02-28 14:41:05,579 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-28 14:41:05,582 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-28 14:41:05,592 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-28 14:41:05,606 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-28 14:41:05,607 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-28 14:41:05,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-28 14:41:05,619 : INFO : EPOCH - 3 : training on 609446 raw words (389489 effective words) took 0.6s, 655631 effective words/s\n",
      "2019-02-28 14:41:06,099 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-28 14:41:06,102 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-28 14:41:06,110 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-28 14:41:06,117 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-28 14:41:06,124 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-28 14:41:06,127 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-28 14:41:06,127 : INFO : EPOCH - 4 : training on 609446 raw words (389657 effective words) took 0.5s, 778472 effective words/s\n",
      "2019-02-28 14:41:06,583 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-28 14:41:06,587 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-28 14:41:06,591 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-28 14:41:06,605 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-28 14:41:06,610 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-28 14:41:06,613 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-28 14:41:06,613 : INFO : EPOCH - 5 : training on 609446 raw words (389314 effective words) took 0.5s, 810885 effective words/s\n",
      "2019-02-28 14:41:06,614 : INFO : training on a 3047230 raw words (1947212 effective words) took 2.9s, 677585 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# punkt sentence level tokenizer\n",
    "sent_lst = []\n",
    "for doc in features_train:\n",
    "    sentences = nltk.tokenize.sent_tokenize(doc)\n",
    "    for sent in sentences:\n",
    "        word_lst = [w for w in nltk.tokenize.word_tokenize(sent) if w.isalnum()]\n",
    "        sent_lst.append(word_lst)\n",
    "        \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "word2vec_model = gensim.models.Word2Vec(sentences=sent_lst,\n",
    "                                        min_count=6,\n",
    "                                        size=EMBEDDING_DIM,\n",
    "                                        sg=1,\n",
    "                                        workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4665 word vectors\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for word in word2vec_model.wv.vocab:\n",
    "    coefs = np.asarray(word2vec_model.wv[word], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "print('Total %s word vectors' % len(embeddings_index))\n",
    "\n",
    "# Initial word embedding\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tok.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None and i < VOCAB_SIZE:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4665 word vectors\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for word in word2vec_model.wv.vocab:\n",
    "    coefs = np.asarray(word2vec_model.wv[word], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "print('Total %s word vectors' % len(embeddings_index))\n",
    "\n",
    "# Initial word embedding\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tok.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None and i < VOCAB_SIZE:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_create_train(labels, learning_rate, lstm_dim, batch_size, num_epochs, optimizer_param, regularization=1e-7):\n",
    "    \n",
    "    l2_reg = regularizers.l2(regularization)\n",
    "    \n",
    "    # init model\n",
    "    embedding_layer = Embedding(VOCAB_SIZE,\n",
    "                                EMBEDDING_DIM,\n",
    "                                input_length=MAX_DOC_LEN,\n",
    "                                trainable=True,\n",
    "                                mask_zero=False,\n",
    "                                embeddings_regularizer=l2_reg,\n",
    "                                weights=[embedding_matrix])\n",
    "    lstm_layer = LSTM(units=lstm_dim, kernel_regularizer=l2_reg)\n",
    "    dense_layer = Dense(n_classes,\n",
    "                        activation='softmax', \n",
    "                        kernel_regularizer=l2_reg)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(lstm_layer))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(dense_layer)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer_param,\n",
    "                  metrics=['acc'])\n",
    "    history = History()\n",
    "    csv_logger = CSVLogger('./LSTM/text/{}_{}_{}_{}.log'.format(learning_rate, regularization, batch_size, num_epochs),\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "    t1 = time.time()\n",
    "    # model fit\n",
    "    model.fit(train_seq,\n",
    "              labels.astype('float32'),\n",
    "              batch_size=batch_size,\n",
    "              epochs=num_epochs,\n",
    "              callbacks=[history, csv_logger],\n",
    "              verbose=2)\n",
    "    t2 = time.time()\n",
    "    # save hdf5\n",
    "    model.save('./LSTM/text/{}_{}_{}_{}_model.h5'.format(learning_rate, regularization, batch_size, num_epochs))\n",
    "    np.savetxt('./LSTM/text/{}_{}_{}_{}_time.txt'.format(learning_rate, regularization, batch_size, num_epochs), \n",
    "               [regularization, (t2-t1) / 3600])\n",
    "    with open('./LSTM/text/{}_{}_{}_{}_history.txt'.format(learning_rate, regularization, batch_size, num_epochs), \"w\") as res_file:\n",
    "        res_file.write(str(history.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 83s - loss: 0.4703 - acc: 0.7836\n",
      "Epoch 2/30\n",
      " - 86s - loss: 0.4204 - acc: 0.8170\n",
      "Epoch 3/30\n",
      " - 85s - loss: 0.4032 - acc: 0.8289\n",
      "Epoch 4/30\n",
      " - 82s - loss: 0.3942 - acc: 0.8337\n",
      "Epoch 5/30\n",
      " - 84s - loss: 0.3795 - acc: 0.8407\n",
      "Epoch 6/30\n",
      " - 82s - loss: 0.3734 - acc: 0.8450\n",
      "Epoch 7/30\n",
      " - 82s - loss: 0.3662 - acc: 0.8482\n",
      "Epoch 8/30\n",
      " - 84s - loss: 0.3618 - acc: 0.8506\n",
      "Epoch 9/30\n",
      " - 82s - loss: 0.3556 - acc: 0.8519\n",
      "Epoch 10/30\n",
      " - 83s - loss: 0.3525 - acc: 0.8550\n",
      "Epoch 11/30\n",
      " - 83s - loss: 0.3495 - acc: 0.8564\n",
      "Epoch 12/30\n",
      " - 82s - loss: 0.3462 - acc: 0.8593\n",
      "Epoch 13/30\n",
      " - 84s - loss: 0.3408 - acc: 0.8612\n",
      "Epoch 14/30\n",
      " - 86s - loss: 0.3431 - acc: 0.8593\n",
      "Epoch 15/30\n",
      " - 82s - loss: 0.3372 - acc: 0.8628\n",
      "Epoch 16/30\n",
      " - 83s - loss: 0.3374 - acc: 0.8611\n",
      "Epoch 17/30\n",
      " - 82s - loss: 0.3388 - acc: 0.8623\n",
      "Epoch 18/30\n",
      " - 84s - loss: 0.3320 - acc: 0.8641\n",
      "Epoch 19/30\n",
      " - 83s - loss: 0.3289 - acc: 0.8665\n",
      "Epoch 20/30\n",
      " - 82s - loss: 0.3278 - acc: 0.8687\n",
      "Epoch 21/30\n",
      " - 84s - loss: 0.3232 - acc: 0.8709\n",
      "Epoch 22/30\n",
      " - 82s - loss: 0.3223 - acc: 0.8701\n",
      "Epoch 23/30\n",
      " - 83s - loss: 0.3188 - acc: 0.8736\n",
      "Epoch 24/30\n",
      " - 84s - loss: 0.3185 - acc: 0.8742\n",
      "Epoch 25/30\n",
      " - 82s - loss: 0.3150 - acc: 0.8737\n",
      "Epoch 26/30\n",
      " - 82s - loss: 0.3119 - acc: 0.8757\n",
      "Epoch 27/30\n",
      " - 82s - loss: 0.3109 - acc: 0.8769\n",
      "Epoch 28/30\n",
      " - 84s - loss: 0.3087 - acc: 0.8764\n",
      "Epoch 29/30\n",
      " - 82s - loss: 0.3069 - acc: 0.8776\n",
      "Epoch 30/30\n",
      " - 82s - loss: 0.3056 - acc: 0.8773\n",
      "Learning rate: 0.1 Regularization: 0 Batch size: 32 Epoch: 30\n",
      "Accuracy = 0.8666666666666667 \t AUC = 0.9318612891842615\n"
     ]
    }
   ],
   "source": [
    "L = 1e-1\n",
    "R = 0\n",
    "B = 32\n",
    "E = 30\n",
    "lstm_create_train(labels=text_recognition_labels,\n",
    "                                  learning_rate=L,\n",
    "                                  lstm_dim=250, \n",
    "                                  batch_size=B,\n",
    "                                  num_epochs=E, \n",
    "                                  optimizer_param=SGD(lr=L, nesterov=True),\n",
    "                                  regularization=R)\n",
    "model = load_model('./LSTM/text/{}_{}_{}_{}_model.h5'.format(L,R,B,E))\n",
    "preds = model.predict(val_seq, verbose=0)\n",
    "print(\"Learning rate: {} Regularization: {} Batch size: {} Epoch: {}\".format(L,R,B,E))\n",
    "print((\"Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(txt_val, preds.argmax(axis=1)), \n",
    "                                                            roc_auc_score(txt_val, preds[:,1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 93s - loss: 0.4691 - acc: 0.7830\n",
      "Epoch 2/30\n",
      " - 91s - loss: 0.4214 - acc: 0.8152\n",
      "Epoch 3/30\n",
      " - 92s - loss: 0.4033 - acc: 0.8302\n",
      "Epoch 4/30\n",
      " - 91s - loss: 0.3901 - acc: 0.8364\n",
      "Epoch 5/30\n",
      " - 93s - loss: 0.3807 - acc: 0.8425\n",
      "Epoch 6/30\n",
      " - 92s - loss: 0.3750 - acc: 0.8449\n",
      "Epoch 7/30\n",
      " - 91s - loss: 0.3667 - acc: 0.8493\n",
      "Epoch 8/30\n",
      " - 93s - loss: 0.3628 - acc: 0.8484\n",
      "Epoch 9/30\n"
     ]
    }
   ],
   "source": [
    "L = 1e-1\n",
    "R = 0\n",
    "B = 32\n",
    "E = 30\n",
    "lstm_create_train(labels=text_recognition_labels,\n",
    "                                  learning_rate=L,\n",
    "                                  lstm_dim=275, \n",
    "                                  batch_size=B,\n",
    "                                  num_epochs=E, \n",
    "                                  optimizer_param=SGD(lr=L, nesterov=True),\n",
    "                                  regularization=R)\n",
    "model = load_model('./LSTM/text/{}_{}_{}_{}_model.h5'.format(L,R,B,E))\n",
    "preds = model.predict(val_seq, verbose=0)\n",
    "print(\"Learning rate: {} Regularization: {} Batch size: {} Epoch: {}\".format(L,R,B,E))\n",
    "print((\"Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(txt_val, preds.argmax(axis=1)), \n",
    "                                                            roc_auc_score(txt_val, preds[:,1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
