{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from util import *\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=10)\n",
    "\n",
    "# for LSTM (keras with tf backend)\n",
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "os.environ['KERAS_BACKEND']='cntk'\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.callbacks import History, CSVLogger\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "MAX_DOC_LEN = 40\n",
    "VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vizwiz_features_train_color = pd.read_csv('azure_features_images/data/vizwiz_train_color_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "vizwiz_features_train_text = pd.read_csv('azure_features_images/data/vizwiz_train_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vizwiz_features_val_color = pd.read_csv('azure_features_images/data/vizwiz_val_color_recognition.csv',\n",
    "                                  delimiter=';', engine='python',\n",
    "                                  dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                  quotechar='\"', error_bad_lines=False)\n",
    "vizwiz_features_val_text = pd.read_csv('azure_features_images/data/vizwiz_val_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vqa_features_train_color = pd.read_csv('azure_features_images/data/vqa_train_color_recognition.csv',\n",
    "                                 delimiter=';', engine='python', \n",
    "                                 dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                 quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_train_text = pd.read_csv('azure_features_images/data/vqa_train_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_val_color = pd.read_csv('azure_features_images/data/vqa_val_color_recognition.csv',\n",
    "                               delimiter=';', engine='python',\n",
    "                               dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                               quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_val_text = pd.read_csv('azure_features_images/data/vqa_val_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vizwiz_targets_train = pd.read_csv('../vizwiz_skill_typ_train.csv',\n",
    "                                   delimiter=',', quotechar='\"',\n",
    "                                   engine='python', error_bad_lines=False)\n",
    "vizwiz_targets_val = pd.read_csv('../vizwiz_skill_typ_val.csv',\n",
    "                                 delimiter=',', quotechar='\"', engine='python', error_bad_lines=False)\n",
    "vqa_targets_train = pd.read_csv('../vqa_skill_typ_train.csv',\n",
    "                               engine='python', quotechar='\"', error_bad_lines=False)\n",
    "vqa_targets_val = pd.read_csv('../vqa_skill_typ_val.csv',\n",
    "                               engine='python', quotechar='\"', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>ocr_text</th>\n",
       "      <th>handwritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VizWiz_train_000000000000.jpg</td>\n",
       "      <td>What's the name of this product?</td>\n",
       "      <td>['b', 'sil', 'leaves', '0.62', 'oz', '(170)']</td>\n",
       "      <td>['NET WT O. 62 02 ( 179)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VizWiz_train_000000000001.jpg</td>\n",
       "      <td>Can you tell me what is in this can please?</td>\n",
       "      <td>[]</td>\n",
       "      <td>['^TAKE Three 1^']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             qid                                     question  \\\n",
       "0  VizWiz_train_000000000000.jpg             What's the name of this product?   \n",
       "1  VizWiz_train_000000000001.jpg  Can you tell me what is in this can please?   \n",
       "\n",
       "                                        ocr_text            handwritten_text  \n",
       "0  ['b', 'sil', 'leaves', '0.62', 'oz', '(170)']  ['NET WT O. 62 02 ( 179)']  \n",
       "1                                             []          ['^TAKE Three 1^']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizwiz_features_train_text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_feature_target(feature_df_text, feature_df_color, target_df):\n",
    "\n",
    "    feature_text = copy.deepcopy(feature_df_text)\n",
    "    feature_color = copy.deepcopy(feature_df_color)\n",
    "    target = copy.deepcopy(target_df)\n",
    "\n",
    "    feature_text.rename({'qid': 'QID'}, axis=1, inplace=True)\n",
    "    feature_text.set_index('QID', inplace=True)\n",
    "\n",
    "    feature_color.rename({'qid': 'QID'}, axis=1, inplace=True)\n",
    "    feature_color.set_index('QID', inplace=True)\n",
    "\n",
    "    features = feature_text.join(feature_color[['descriptions','tags','dominant_colors']],\n",
    "                                 on='QID',\n",
    "                                 how='outer')\n",
    "\n",
    "    target = target[['QID', 'IMG', 'QSN', 'TXT', 'OBJ', 'COL', 'CNT', 'OTH']]\n",
    "    target.set_index('QID', inplace=True)\n",
    "    target = target.astype(dtype=str)\n",
    "\n",
    "    df = target.join(features, on='QID', how='inner')\n",
    "    df['descriptions'].astype(list)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vizwiz_train = join_feature_target(vizwiz_features_train_text, \n",
    "                                   vizwiz_features_train_color,\n",
    "                                   vizwiz_targets_train)\n",
    "vizwiz_val = join_feature_target(vizwiz_features_val_text,\n",
    "                                vizwiz_features_val_color,\n",
    "                                vizwiz_targets_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'text': 'a bottle of wine on a table', 'confidence': 0.7408009412153109}]\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizwiz_train['descriptions'][0]# .split(\":\")[1].split(\",\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizwiz_train['descriptions'].apply(lambda x: x[0].split(\":\")[1].split(\",\"))\n",
    "#train_questions = vizwiz_train['QSN'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IMG', 'QSN', 'TXT', 'OBJ', 'COL', 'CNT', 'OTH', 'question', 'ocr_text',\n",
       "       'handwritten_text', 'descriptions', 'tags', 'dominant_colors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizwiz_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and Ys\n",
    "features_train=vizwiz_train[['QSN', 'descriptions', 'tags', 'dominant_colors', 'handwritten_text', 'ocr_text']].values\n",
    "txt_train=vizwiz_train[\"TXT\"].values\n",
    "obj_train=vizwiz_train[\"OBJ\"].values\n",
    "col_train=vizwiz_train[\"COL\"].values\n",
    "cnt_train=vizwiz_train[\"CNT\"].values\n",
    "\n",
    "features_train=vizwiz_train[['QSN', 'descriptions', 'tags', 'dominant_colors', 'handwritten_text', 'ocr_text']]\n",
    "txt_val=vizwiz_val[\"TXT\"].values\n",
    "obj_val=vizwiz_val[\"OBJ\"].values\n",
    "col_val=vizwiz_val[\"COL\"].values\n",
    "cnt_val=vizwiz_val[\"CNT\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize, create seqs, pad\n",
    "tok = Tokenizer(num_words=VOCAB_SIZE, lower=True, split=\" \")\n",
    "tok.fit_on_texts(ques_train)\n",
    "train_seq = tok.texts_to_sequences(ques_train)\n",
    "train_seq = sequence.pad_sequences(train_seq, maxlen=MAX_DOC_LEN)\n",
    "val_seq = tok.texts_to_sequences(ques_val)\n",
    "val_seq = sequence.pad_sequences(val_seq, maxlen=MAX_DOC_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews by class in training set\n",
      "[6247. 8010.]\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(txt_train))\n",
    "labels = labels.astype('float32')\n",
    "print('Number of reviews by class in training set')\n",
    "print(labels.sum(axis=0))\n",
    "n_classes = labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use LSTM to predict\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "\n",
    "os.environ['KERAS_BACKEND']='cntk'\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.callbacks import History, CSVLogger\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "MAX_DOC_LEN = 40\n",
    "VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize, create seqs, pad\n",
    "tok = Tokenizer(num_words=VOCAB_SIZE, lower=True, split=\" \")\n",
    "tok.fit_on_texts(ques_train)\n",
    "train_seq = tok.texts_to_sequences(ques_train)\n",
    "train_seq = sequence.pad_sequences(train_seq, maxlen=MAX_DOC_LEN)\n",
    "val_seq = tok.texts_to_sequences(ques_val)\n",
    "val_seq = sequence.pad_sequences(val_seq, maxlen=MAX_DOC_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews by class in training set\n",
      "[6247. 8010.]\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(txt_train))\n",
    "labels = labels.astype('float32')\n",
    "print('Number of reviews by class in training set')\n",
    "print(labels.sum(axis=0))\n",
    "n_classes = labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/edithzeng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "sent_lst = []\n",
    "\n",
    "for doc in ques_train:\n",
    "    sentences = nltk.tokenize.sent_tokenize(doc)\n",
    "    for sent in sentences:\n",
    "        word_lst = [w for w in nltk.tokenize.word_tokenize(sent) if w.isalnum()]\n",
    "        sent_lst.append(word_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 22:58:43,023 : INFO : collecting all words and their counts\n",
      "2019-02-25 22:58:43,024 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-02-25 22:58:43,035 : INFO : PROGRESS: at sentence #10000, processed 54548 words, keeping 2480 word types\n",
      "2019-02-25 22:58:43,042 : INFO : collected 3155 word types from a corpus of 88885 raw words and 16214 sentences\n",
      "2019-02-25 22:58:43,043 : INFO : Loading a fresh vocabulary\n",
      "2019-02-25 22:58:43,045 : INFO : effective_min_count=6 retains 749 unique words (23% of original 3155, drops 2406)\n",
      "2019-02-25 22:58:43,046 : INFO : effective_min_count=6 leaves 84818 word corpus (95% of original 88885, drops 4067)\n",
      "2019-02-25 22:58:43,048 : INFO : deleting the raw counts dictionary of 3155 items\n",
      "2019-02-25 22:58:43,049 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2019-02-25 22:58:43,049 : INFO : downsampling leaves estimated 35321 word corpus (41.6% of prior 84818)\n",
      "2019-02-25 22:58:43,051 : INFO : estimated required memory for 749 words and 100 dimensions: 973700 bytes\n",
      "2019-02-25 22:58:43,051 : INFO : resetting layer weights\n",
      "2019-02-25 22:58:43,064 : INFO : training model with 6 workers on 749 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-25 22:58:43,129 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-25 22:58:43,132 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-25 22:58:43,135 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-25 22:58:43,139 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-25 22:58:43,143 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-25 22:58:43,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-25 22:58:43,144 : INFO : EPOCH - 1 : training on 88885 raw words (35265 effective words) took 0.1s, 666829 effective words/s\n",
      "2019-02-25 22:58:43,184 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-25 22:58:43,187 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-25 22:58:43,190 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-25 22:58:43,190 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-25 22:58:43,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-25 22:58:43,195 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-25 22:58:43,196 : INFO : EPOCH - 2 : training on 88885 raw words (35491 effective words) took 0.0s, 875029 effective words/s\n",
      "2019-02-25 22:58:43,236 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-25 22:58:43,236 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-25 22:58:43,238 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-25 22:58:43,239 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-25 22:58:43,244 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-25 22:58:43,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-25 22:58:43,246 : INFO : EPOCH - 3 : training on 88885 raw words (35335 effective words) took 0.0s, 850067 effective words/s\n",
      "2019-02-25 22:58:43,285 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-25 22:58:43,286 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-25 22:58:43,287 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-25 22:58:43,288 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-25 22:58:43,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-25 22:58:43,294 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-25 22:58:43,295 : INFO : EPOCH - 4 : training on 88885 raw words (35176 effective words) took 0.0s, 898399 effective words/s\n",
      "2019-02-25 22:58:43,333 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-25 22:58:43,336 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-25 22:58:43,336 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-25 22:58:43,337 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-25 22:58:43,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-25 22:58:43,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-25 22:58:43,346 : INFO : EPOCH - 5 : training on 88885 raw words (35378 effective words) took 0.0s, 835879 effective words/s\n",
      "2019-02-25 22:58:43,346 : INFO : training on a 444425 raw words (176645 effective words) took 0.3s, 626550 effective words/s\n",
      "2019-02-25 22:58:43,347 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "# use skip-gram\n",
    "word2vec_model = gensim.models.Word2Vec(sentences=sent_lst, min_count=6, size=EMBEDDING_DIM, sg=1, workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 749 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for word in word2vec_model.wv.vocab:\n",
    "    coefs = np.asarray(word2vec_model.wv[word], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "print('Total %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# Initial word embedding\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tok.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None and i < VOCAB_SIZE:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
