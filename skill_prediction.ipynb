{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skill label prediction with image-based features (text and color with descriptive tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/edithzeng/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=10)\n",
    "\n",
    "# for LSTM (keras with tf backend)\n",
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "os.environ['KERAS_BACKEND']='cntk'\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.callbacks import History, CSVLogger\n",
    "from keras.utils import to_categorical\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "MAX_DOC_LEN = 40\n",
    "VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vizwiz_features_train_color = pd.read_csv('azure_features_images/data/vizwiz_train_color_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "vizwiz_features_train_text = pd.read_csv('azure_features_images/data/vizwiz_train_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vizwiz_features_val_color = pd.read_csv('azure_features_images/data/vizwiz_val_color_recognition.csv',\n",
    "                                  delimiter=';', engine='python',\n",
    "                                  dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                  quotechar='\"', error_bad_lines=False)\n",
    "vizwiz_features_val_text = pd.read_csv('azure_features_images/data/vizwiz_val_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vqa_features_train_color = pd.read_csv('azure_features_images/data/vqa_train_color_recognition.csv',\n",
    "                                 delimiter=';', engine='python', \n",
    "                                 dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                                 quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_train_text = pd.read_csv('azure_features_images/data/vqa_train_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_val_color = pd.read_csv('azure_features_images/data/vqa_val_color_recognition.csv',\n",
    "                               delimiter=';', engine='python',\n",
    "                               dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'tags':list, 'dominant_colors':list},\n",
    "                               quotechar='\"', error_bad_lines=False)\n",
    "vqa_features_val_text = pd.read_csv('azure_features_images/data/vqa_val_text_recognition.csv',\n",
    "                                    delimiter=';', engine='python', \n",
    "                                    dtype={'qid':str, 'question':str, 'descriptions':list,\n",
    "                                          'ocr_text':list, 'handwritten_text':list},\n",
    "                                    quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "\n",
    "vizwiz_targets_train = pd.read_csv('../vizwiz_skill_typ_train.csv',\n",
    "                                   delimiter=',', quotechar='\"',\n",
    "                                   engine='python', error_bad_lines=False)\n",
    "vizwiz_targets_val = pd.read_csv('../vizwiz_skill_typ_val.csv',\n",
    "                                 delimiter=',', quotechar='\"', engine='python', error_bad_lines=False)\n",
    "vqa_targets_train = pd.read_csv('../vqa_skill_typ_train.csv',\n",
    "                               engine='python', quotechar='\"', error_bad_lines=False)\n",
    "vqa_targets_val = pd.read_csv('../vqa_skill_typ_val.csv',\n",
    "                               engine='python', quotechar='\"', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>ocr_text</th>\n",
       "      <th>handwritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VizWiz_train_000000000000.jpg</td>\n",
       "      <td>What's the name of this product?</td>\n",
       "      <td>['b', 'sil', 'leaves', '0.62', 'oz', '(170)']</td>\n",
       "      <td>['NET WT O. 62 02 ( 179)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VizWiz_train_000000000001.jpg</td>\n",
       "      <td>Can you tell me what is in this can please?</td>\n",
       "      <td>[]</td>\n",
       "      <td>['^TAKE Three 1^']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             qid                                     question  \\\n",
       "0  VizWiz_train_000000000000.jpg             What's the name of this product?   \n",
       "1  VizWiz_train_000000000001.jpg  Can you tell me what is in this can please?   \n",
       "\n",
       "                                        ocr_text            handwritten_text  \n",
       "0  ['b', 'sil', 'leaves', '0.62', 'oz', '(170)']  ['NET WT O. 62 02 ( 179)']  \n",
       "1                                             []          ['^TAKE Three 1^']  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizwiz_features_train_text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMG</th>\n",
       "      <th>QSN</th>\n",
       "      <th>TXT</th>\n",
       "      <th>OBJ</th>\n",
       "      <th>COL</th>\n",
       "      <th>CNT</th>\n",
       "      <th>OTH</th>\n",
       "      <th>question</th>\n",
       "      <th>ocr_text</th>\n",
       "      <th>handwritten_text</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>tags</th>\n",
       "      <th>dominant_colors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VizWiz_train_000000009759.jpg</th>\n",
       "      <td>VizWiz_train_000000009759.jpg</td>\n",
       "      <td>what's this?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what's this?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'text': 'a close up of a computer', 'confide...</td>\n",
       "      <td>['sitting', 'man', 'computer', 'black', 'stand...</td>\n",
       "      <td>['Grey', 'White']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         IMG           QSN  \\\n",
       "QID                                                                          \n",
       "VizWiz_train_000000009759.jpg  VizWiz_train_000000009759.jpg  what's this?   \n",
       "\n",
       "                              TXT OBJ COL CNT OTH      question ocr_text  \\\n",
       "QID                                                                        \n",
       "VizWiz_train_000000009759.jpg   0   1   0   0   0  what's this?       []   \n",
       "\n",
       "                              handwritten_text  \\\n",
       "QID                                              \n",
       "VizWiz_train_000000009759.jpg               []   \n",
       "\n",
       "                                                                    descriptions  \\\n",
       "QID                                                                                \n",
       "VizWiz_train_000000009759.jpg  [{'text': 'a close up of a computer', 'confide...   \n",
       "\n",
       "                                                                            tags  \\\n",
       "QID                                                                                \n",
       "VizWiz_train_000000009759.jpg  ['sitting', 'man', 'computer', 'black', 'stand...   \n",
       "\n",
       "                                 dominant_colors  \n",
       "QID                                               \n",
       "VizWiz_train_000000009759.jpg  ['Grey', 'White']  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizwiz_train.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_feature_target(feature_df_text, feature_df_color, target_df):\n",
    "    feature_text = copy.deepcopy(feature_df_text)\n",
    "    feature_color = copy.deepcopy(feature_df_color)\n",
    "    target = copy.deepcopy(target_df)\n",
    "    # text features \n",
    "    feature_text.rename({'qid': 'QID'}, axis=1, inplace=True)\n",
    "    feature_text.set_index('QID', inplace=True)\n",
    "    # color features\n",
    "    feature_color.rename({'qid': 'QID'}, axis=1, inplace=True)\n",
    "    feature_color.set_index('QID', inplace=True)\n",
    "    # join features\n",
    "    features = feature_text.join(feature_color[['descriptions','tags','dominant_colors']],\n",
    "                                 on='QID',\n",
    "                                 how='outer')\n",
    "    # join features with target\n",
    "    target = target[['QID', 'IMG', 'QSN', 'TXT', 'OBJ', 'COL', 'CNT', 'OTH']]\n",
    "    target.set_index('QID', inplace=True)\n",
    "    target = target.astype(dtype=str)\n",
    "    df = target.join(features, on='QID', how='inner')\n",
    "    df['descriptions'].astype(list)\n",
    "    return df\n",
    "\n",
    "def lem(s):\n",
    "    arr = s.split(\" \")\n",
    "    lem = WordNetLemmatizer()\n",
    "    op = \"\"\n",
    "    for w in arr:\n",
    "        word = lem.lemmatize(w) + ' '\n",
    "        op += word\n",
    "    return op\n",
    "\n",
    "def preprocess_text(feature_columns):\n",
    "    \"\"\" output an nparray with single document per data point \"\"\"\n",
    "    ip = copy.deepcopy(feature_columns).values\n",
    "    op = []\n",
    "    for i in range(ip.shape[0]):\n",
    "        doc      =  \"\"\n",
    "        for j in range(ip.shape[1]):\n",
    "            # clean up chars\n",
    "            s    =  str(ip[i][j])\n",
    "            s    =  s.translate({ord(c): \"\" for c in \"!@#$%^&*()[]{};:,./<>?\\|`~-=_+'\"}).lower() + \" \"\n",
    "            if j == 1:             # clean descriptions\n",
    "                s = re.sub(r'confidence\\s+\\d+', '', s)\n",
    "                s = re.sub(r'text', '', s)\n",
    "            # lexicon normalize\n",
    "            s    = lem(s)\n",
    "            doc  += (s.strip())\n",
    "        op.append(doc)\n",
    "    op = np.asarray(op)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vizwiz_train   = join_feature_target(vizwiz_features_train_text, \n",
    "                                   vizwiz_features_train_color, \n",
    "                                   vizwiz_targets_train)\n",
    "vizwiz_val     = join_feature_target(vizwiz_features_val_text, \n",
    "                                 vizwiz_features_val_color, \n",
    "                                 vizwiz_targets_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y\n",
    "features_train = cleanse(vizwiz_train[['QSN', \n",
    "                                       'descriptions', 'tags', 'dominant_colors', \n",
    "                                       'handwritten_text', 'ocr_text']])\n",
    "txt_train      = vizwiz_train[\"TXT\"].values\n",
    "obj_train      = vizwiz_train[\"OBJ\"].values\n",
    "col_train      = vizwiz_train[\"COL\"].values\n",
    "cnt_train      = vizwiz_train[\"CNT\"].values\n",
    "\n",
    "features_val   = cleanse(vizwiz_val[['QSN', \n",
    "                                     'descriptions', 'tags', 'dominant_colors', \n",
    "                                     'handwritten_text', 'ocr_text']])\n",
    "txt_val        = vizwiz_val[\"TXT\"].values\n",
    "obj_val        = vizwiz_val[\"OBJ\"].values\n",
    "col_val        = vizwiz_val[\"COL\"].values\n",
    "cnt_val        = vizwiz_val[\"CNT\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testing what is this  floor indoor sitting room standing cat black living woman white young playing kitchen laying table man night game holding sink oven grey   '"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[random.randint(0,len(features_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is this medicine text a close up of a bottle  indoor sitting bottle green table small food black counter white lotion fruit laying phone brush grey active ingredient  new cetirizine hot 10 ndc 30142  458  95 uses temporary relievesto  runny nose  sneezing 1 warnings do not use in 24 hour ingredients or to an artnozz have liver or kidney deese wey all day doctor or pharmacistbe this product \" drowsiness allergy tranquilizers may not machinery stop use and medical help right away  cetirizine hydrochloride tablets  recommended  i prays 10 ing  antihistamine children  in case downdue directions adults and 45 tablets active i gredie•ltp\" hoc 3014245895 24 hour allday allergy ceirizåne hydrochloride tablets 10 mgantihistamine 45 tablets '"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_val[random.randint(0,len(features_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "tok        = Tokenizer(num_words=VOCAB_SIZE, \n",
    "                       filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                       lower=True,\n",
    "                       split=\" \")\n",
    "tok.fit_on_texts(features_train)\n",
    "\n",
    "# create sequences & pad\n",
    "train_seq  = tok.texts_to_sequences(features_train)\n",
    "train_seq  = sequence.pad_sequences(train_seq, maxlen=MAX_DOC_LEN)\n",
    "val_seq    = tok.texts_to_sequences(features_val)\n",
    "val_seq    = sequence.pad_sequences(val_seq, maxlen=MAX_DOC_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples each class - Vizwiz - train\n",
      "Text recognition [6247. 8010.]\n",
      "Color recognition [8844. 5413.]\n"
     ]
    }
   ],
   "source": [
    "# check class distribution\n",
    "text_recognition_labels = to_categorical(np.asarray(txt_train)).astype('float32')\n",
    "color_recognition_labels = to_categorical(np.asarray(col_train)).astype('float32')\n",
    "print('Number of samples each class - Vizwiz - train')\n",
    "print('Text recognition', text_recognition_labels.sum(axis=0))\n",
    "print('Color recognition', color_recognition_labels.sum(axis=0))\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model (skip-gram word2vec)\n",
    "config for cpu only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import gzip\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'cntk'\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.callbacks import History, CSVLogger\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import nltk \n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "MAX_DOC_LEN = 40\n",
    "VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/edithzeng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# punkt sentence level tokenizer\n",
    "nltk.download('punkt')\n",
    "sent_lst = []\n",
    "for doc in features_train:\n",
    "    sentences = nltk.tokenize.sent_tokenize(doc)\n",
    "    for sent in sentences:\n",
    "        word_lst = [w for w in nltk.tokenize.word_tokenize(sent) if w.isalnum()]\n",
    "        sent_lst.append(word_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 18:40:10,420 : INFO : collecting all words and their counts\n",
      "2019-02-26 18:40:10,421 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-02-26 18:40:10,484 : INFO : PROGRESS: at sentence #10000, processed 392086 words, keeping 26072 word types\n",
      "2019-02-26 18:40:10,510 : INFO : collected 33236 word types from a corpus of 554278 raw words and 14257 sentences\n",
      "2019-02-26 18:40:10,511 : INFO : Loading a fresh vocabulary\n",
      "2019-02-26 18:40:10,534 : INFO : effective_min_count=6 retains 3750 unique words (11% of original 33236, drops 29486)\n",
      "2019-02-26 18:40:10,535 : INFO : effective_min_count=6 leaves 511934 word corpus (92% of original 554278, drops 42344)\n",
      "2019-02-26 18:40:10,544 : INFO : deleting the raw counts dictionary of 33236 items\n",
      "2019-02-26 18:40:10,545 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2019-02-26 18:40:10,545 : INFO : downsampling leaves estimated 321841 word corpus (62.9% of prior 511934)\n",
      "2019-02-26 18:40:10,553 : INFO : estimated required memory for 3750 words and 100 dimensions: 4875000 bytes\n",
      "2019-02-26 18:40:10,553 : INFO : resetting layer weights\n",
      "2019-02-26 18:40:10,626 : INFO : training model with 6 workers on 3750 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 18:40:11,023 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-26 18:40:11,035 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-26 18:40:11,038 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-26 18:40:11,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 18:40:11,048 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 18:40:11,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 18:40:11,049 : INFO : EPOCH - 1 : training on 554278 raw words (321408 effective words) took 0.4s, 771352 effective words/s\n",
      "2019-02-26 18:40:11,430 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-26 18:40:11,433 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-26 18:40:11,438 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-26 18:40:11,440 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 18:40:11,442 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 18:40:11,449 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 18:40:11,450 : INFO : EPOCH - 2 : training on 554278 raw words (321797 effective words) took 0.4s, 816586 effective words/s\n",
      "2019-02-26 18:40:11,824 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-26 18:40:11,831 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-26 18:40:11,836 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-26 18:40:11,841 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 18:40:11,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 18:40:11,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 18:40:11,849 : INFO : EPOCH - 3 : training on 554278 raw words (321919 effective words) took 0.4s, 818548 effective words/s\n",
      "2019-02-26 18:40:12,222 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-26 18:40:12,228 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-26 18:40:12,233 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-26 18:40:12,238 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 18:40:12,245 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 18:40:12,249 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 18:40:12,250 : INFO : EPOCH - 4 : training on 554278 raw words (321365 effective words) took 0.4s, 814642 effective words/s\n",
      "2019-02-26 18:40:12,633 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-26 18:40:12,638 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-26 18:40:12,643 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-26 18:40:12,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 18:40:12,651 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 18:40:12,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 18:40:12,653 : INFO : EPOCH - 5 : training on 554278 raw words (321493 effective words) took 0.4s, 809577 effective words/s\n",
      "2019-02-26 18:40:12,654 : INFO : training on a 2771390 raw words (1607982 effective words) took 2.0s, 793188 effective words/s\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "word2vec_model = gensim.models.Word2Vec(sentences=sent_lst,\n",
    "                                        min_count=6,\n",
    "                                        size=EMBEDDING_DIM,\n",
    "                                        sg=1,\n",
    "                                        workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 3750 word vectors\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for word in word2vec_model.wv.vocab:\n",
    "    coefs = np.asarray(word2vec_model.wv[word], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "print('Total %s word vectors' % len(embeddings_index))\n",
    "\n",
    "# Initial word embedding\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tok.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None and i < VOCAB_SIZE:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_create_train(labels, lstm_dim, batch_size, num_epochs, optimizer_param, regularization=1e-7):\n",
    "    \n",
    "    l2_reg = regularizers.l2(regularization)\n",
    "    \n",
    "    # init model\n",
    "    embedding_layer = Embedding(VOCAB_SIZE,\n",
    "                                EMBEDDING_DIM,\n",
    "                                input_length=MAX_DOC_LEN,\n",
    "                                trainable=True,\n",
    "                                mask_zero=False,\n",
    "                                embeddings_regularizer=l2_reg,\n",
    "                                weights=[embedding_matrix])\n",
    "    lstm_layer = LSTM(units=lstm_dim, kernel_regularizer=l2_reg)\n",
    "    dense_layer = Dense(n_classes, activation='softmax', kernel_regularizer=l2_reg)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(lstm_layer))\n",
    "    model.add(Dropout(0.2))  # todo\n",
    "    model.add(dense_layer)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer_param,\n",
    "                  metrics=['acc'])\n",
    "    fname = \"lstm\"\n",
    "    history = History()\n",
    "    csv_logger = CSVLogger('./{0}_{1}.log'.format(fname, regularization),\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "    t1 = time.time()\n",
    "    # model fit\n",
    "    model.fit(train_seq,\n",
    "              labels.astype('float32'),\n",
    "              batch_size=batch_size,\n",
    "              epochs=num_epochs,\n",
    "              callbacks=[history, csv_logger],\n",
    "              verbose=2)\n",
    "    t2 = time.time()\n",
    "    # save h5\n",
    "    model.save('./LSTM/{0}_{1}_model.h5'.format(fname, regularization))\n",
    "    np.savetxt('./LSTM/{0}_{1}_time.txt'.format(fname, regularization), \n",
    "               [regularization, (t2-t1) / 3600])\n",
    "    with open('./LSTM/{0}_{1}_history.txt'.format(fname, regularization), \"w\") as res_file:\n",
    "        res_file.write(str(history.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 15s - loss: 13.2357 - acc: 0.7572\n",
      "Epoch 2/30\n",
      " - 15s - loss: 12.4616 - acc: 0.7983\n",
      "Epoch 3/30\n",
      " - 15s - loss: 11.7785 - acc: 0.8045\n",
      "Epoch 4/30\n",
      " - 15s - loss: 11.1353 - acc: 0.8167\n",
      "Epoch 5/30\n",
      " - 15s - loss: 10.5292 - acc: 0.8219\n",
      "Epoch 6/30\n",
      " - 15s - loss: 9.9641 - acc: 0.8230\n",
      "Epoch 7/30\n",
      " - 15s - loss: 9.4277 - acc: 0.8294\n",
      "Epoch 8/30\n",
      " - 15s - loss: 8.9240 - acc: 0.8287\n",
      "Epoch 9/30\n",
      " - 15s - loss: 8.4473 - acc: 0.8350\n",
      "Epoch 10/30\n",
      " - 15s - loss: 7.9911 - acc: 0.8381\n",
      "Epoch 11/30\n",
      " - 15s - loss: 7.5703 - acc: 0.8397\n",
      "Epoch 12/30\n",
      " - 15s - loss: 7.1678 - acc: 0.8421\n",
      "Epoch 13/30\n",
      " - 15s - loss: 6.7909 - acc: 0.8418\n",
      "Epoch 14/30\n",
      " - 15s - loss: 6.4314 - acc: 0.8452\n",
      "Epoch 15/30\n",
      " - 15s - loss: 6.0942 - acc: 0.8453\n",
      "Epoch 16/30\n",
      " - 15s - loss: 5.7795 - acc: 0.8451\n",
      "Epoch 17/30\n",
      " - 15s - loss: 5.4707 - acc: 0.8482\n",
      "Epoch 18/30\n",
      " - 15s - loss: 5.1938 - acc: 0.8475\n",
      "Epoch 19/30\n",
      " - 15s - loss: 4.9234 - acc: 0.8509\n",
      "Epoch 20/30\n",
      " - 15s - loss: 4.6680 - acc: 0.8500\n",
      "Epoch 21/30\n",
      " - 15s - loss: 4.4286 - acc: 0.8521\n",
      "Epoch 22/30\n",
      " - 15s - loss: 4.2025 - acc: 0.8514\n",
      "Epoch 23/30\n",
      " - 15s - loss: 3.9902 - acc: 0.8528\n",
      "Epoch 24/30\n",
      " - 15s - loss: 3.7867 - acc: 0.8540\n",
      "Epoch 25/30\n",
      " - 15s - loss: 3.5998 - acc: 0.8536\n",
      "Epoch 26/30\n",
      " - 15s - loss: 3.4183 - acc: 0.8580\n",
      "Epoch 27/30\n",
      " - 15s - loss: 3.2484 - acc: 0.8574\n",
      "Epoch 28/30\n",
      " - 15s - loss: 3.0872 - acc: 0.8569\n",
      "Epoch 29/30\n",
      " - 15s - loss: 2.9375 - acc: 0.8550\n",
      "Epoch 30/30\n",
      " - 15s - loss: 2.7983 - acc: 0.8564\n"
     ]
    }
   ],
   "source": [
    "# reduce learning rate for larger batch GD - 85%\n",
    "lstm_create_train(labels=text_recognition_labels,\n",
    "                  lstm_dim=100, \n",
    "                  batch_size=50,\n",
    "                  num_epochs=30, \n",
    "                  optimizer_param=SGD(lr=0.05, nesterov=True),\n",
    "                  regularization=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 15s - loss: 13.1635 - acc: 0.7596\n",
      "Epoch 2/50\n",
      " - 15s - loss: 12.2640 - acc: 0.7968\n",
      "Epoch 3/50\n",
      " - 15s - loss: 11.4644 - acc: 0.8063\n",
      "Epoch 4/50\n",
      " - 15s - loss: 10.7211 - acc: 0.8159\n",
      "Epoch 5/50\n",
      " - 15s - loss: 10.0295 - acc: 0.8230\n",
      "Epoch 6/50\n",
      " - 15s - loss: 9.3818 - acc: 0.8275\n",
      "Epoch 7/50\n",
      " - 15s - loss: 8.7857 - acc: 0.8271\n",
      "Epoch 8/50\n",
      " - 15s - loss: 8.2246 - acc: 0.8319\n",
      "Epoch 9/50\n",
      " - 15s - loss: 7.6998 - acc: 0.8378\n",
      "Epoch 10/50\n",
      " - 15s - loss: 7.2135 - acc: 0.8396\n",
      "Epoch 11/50\n",
      " - 15s - loss: 6.7595 - acc: 0.8407\n",
      "Epoch 12/50\n",
      " - 15s - loss: 6.3373 - acc: 0.8409\n",
      "Epoch 13/50\n",
      " - 15s - loss: 5.9380 - acc: 0.8444\n",
      "Epoch 14/50\n",
      " - 15s - loss: 5.5710 - acc: 0.8445\n",
      "Epoch 15/50\n",
      " - 15s - loss: 5.2227 - acc: 0.8477\n",
      "Epoch 16/50\n",
      " - 15s - loss: 4.8992 - acc: 0.8512\n",
      "Epoch 17/50\n",
      " - 15s - loss: 4.5982 - acc: 0.8507\n",
      "Epoch 18/50\n",
      " - 15s - loss: 4.3205 - acc: 0.8526\n",
      "Epoch 19/50\n",
      " - 15s - loss: 4.0563 - acc: 0.8507\n",
      "Epoch 20/50\n",
      " - 15s - loss: 3.8103 - acc: 0.8528\n",
      "Epoch 21/50\n",
      " - 15s - loss: 3.5844 - acc: 0.8491\n",
      "Epoch 22/50\n",
      " - 15s - loss: 3.3705 - acc: 0.8542\n",
      "Epoch 23/50\n",
      " - 15s - loss: 3.1699 - acc: 0.8565\n",
      "Epoch 24/50\n",
      " - 15s - loss: 2.9825 - acc: 0.8587\n",
      "Epoch 25/50\n",
      " - 15s - loss: 2.8128 - acc: 0.8551\n",
      "Epoch 26/50\n",
      " - 15s - loss: 2.6538 - acc: 0.8551\n",
      "Epoch 27/50\n",
      " - 15s - loss: 2.4989 - acc: 0.8580\n",
      "Epoch 28/50\n",
      " - 15s - loss: 2.3576 - acc: 0.8583\n",
      "Epoch 29/50\n",
      " - 15s - loss: 2.2272 - acc: 0.8558\n",
      "Epoch 30/50\n",
      " - 15s - loss: 2.1030 - acc: 0.8587\n",
      "Epoch 31/50\n",
      " - 15s - loss: 1.9829 - acc: 0.8596\n",
      "Epoch 32/50\n",
      " - 15s - loss: 1.8831 - acc: 0.8583\n",
      "Epoch 33/50\n",
      " - 15s - loss: 1.7816 - acc: 0.8608\n",
      "Epoch 34/50\n",
      " - 15s - loss: 1.6863 - acc: 0.8613\n",
      "Epoch 35/50\n"
     ]
    }
   ],
   "source": [
    "# reduce learning rate for larger batch GD - 85%\n",
    "lstm_create_train(labels=text_recognition_labels,\n",
    "                  lstm_dim=100, \n",
    "                  batch_size=50,\n",
    "                  num_epochs=50, \n",
    "                  optimizer_param=SGD(lr=0.06, nesterov=True),\n",
    "                  regularization=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_create_train(labels=text_recognition_labels,\n",
    "                  lstm_dim=100,\n",
    "                  batch_size=50,\n",
    "                  num_epochs=50,\n",
    "                  optimizer_param=SGD(lr=0.06, nesterov=True),\n",
    "                  regularization=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model('./LSTM/lstm_{0}_model.h5'.format(1e-3))\n",
    "preds = model.predict(val_seq, verbose=0)\n",
    "print((\"Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(txt_val, preds.argmax(axis=1)), \n",
    "       roc_auc_score(txt_val, preds[:,1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_create_train(labels=color_recognition_labels,\n",
    "                  lstm_dim=100, \n",
    "                  batch_size=50,\n",
    "                  num_epochs=30, \n",
    "                  optimizer_param=SGD(lr=0.05, nesterov=True),\n",
    "                  regularization=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_create_train(labels=color_recognition_labels,\n",
    "                  lstm_dim=100, \n",
    "                  batch_size=100,\n",
    "                  num_epochs=30, \n",
    "                  optimizer_param=SGD(lr=0.05, nesterov=True),\n",
    "                  regularization=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_create_train(labels=color_recognition_labels,\n",
    "                  lstm_dim=100, \n",
    "                  batch_size=100,\n",
    "                  num_epochs=30, \n",
    "                  optimizer_param=SGD(lr=0.03, nesterov=True),\n",
    "                  regularization=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_create_train(labels=color_recognition_labels,\n",
    "                  lstm_dim=100, \n",
    "                  batch_size=200,\n",
    "                  num_epochs=30, \n",
    "                  optimizer_param=SGD(lr=0.03, nesterov=True),\n",
    "                  regularization=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
