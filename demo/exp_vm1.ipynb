{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9529360153903546520\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11285289370\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9055805575942443489\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 5cc5:00:00.0, compute capability: 3.7\"\n",
      "]\n",
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5892320181565928352\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11285289370\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13672455238262182027\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 5cc5:00:00.0, compute capability: 3.7\"\n",
      "]\n",
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from extract_features import *\n",
    "from utils import *\n",
    "from preprocessing import *\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: vqa \n",
      "Features: ['QSN', 'descriptions', 'tags', 'dominant_colors', 'handwritten_text', 'ocr_text']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "2019-04-23 11:42:49,119 : INFO : collecting all words and their counts\n",
      "2019-04-23 11:42:49,120 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-04-23 11:42:49,138 : INFO : collected 4567 word types from a corpus of 129923 raw words and 3230 sentences\n",
      "2019-04-23 11:42:49,139 : INFO : Loading a fresh vocabulary\n",
      "2019-04-23 11:42:49,144 : INFO : effective_min_count=6 retains 845 unique words (18% of original 4567, drops 3722)\n",
      "2019-04-23 11:42:49,144 : INFO : effective_min_count=6 leaves 124737 word corpus (96% of original 129923, drops 5186)\n",
      "2019-04-23 11:42:49,147 : INFO : deleting the raw counts dictionary of 4567 items\n",
      "2019-04-23 11:42:49,148 : INFO : sample=0.001 downsamples 76 most-common words\n",
      "2019-04-23 11:42:49,149 : INFO : downsampling leaves estimated 79821 word corpus (64.0% of prior 124737)\n",
      "2019-04-23 11:42:49,151 : INFO : estimated required memory for 845 words and 100 dimensions: 1098500 bytes\n",
      "2019-04-23 11:42:49,152 : INFO : resetting layer weights\n",
      "2019-04-23 11:42:49,171 : INFO : training model with 6 workers on 845 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-04-23 11:42:49,266 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-23 11:42:49,268 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-23 11:42:49,271 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-23 11:42:49,272 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 11:42:49,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 11:42:49,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 11:42:49,291 : INFO : EPOCH - 1 : training on 129923 raw words (79777 effective words) took 0.1s, 693148 effective words/s\n",
      "2019-04-23 11:42:49,387 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-23 11:42:49,389 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-23 11:42:49,392 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-23 11:42:49,394 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 11:42:49,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 11:42:49,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 11:42:49,413 : INFO : EPOCH - 2 : training on 129923 raw words (79685 effective words) took 0.1s, 691028 effective words/s\n",
      "2019-04-23 11:42:49,509 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-23 11:42:49,512 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-23 11:42:49,517 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-23 11:42:49,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 11:42:49,518 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 11:42:49,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 11:42:49,533 : INFO : EPOCH - 3 : training on 129923 raw words (79661 effective words) took 0.1s, 696705 effective words/s\n",
      "2019-04-23 11:42:49,632 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-23 11:42:49,636 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-23 11:42:49,639 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-23 11:42:49,640 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 11:42:49,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 11:42:49,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 11:42:49,662 : INFO : EPOCH - 4 : training on 129923 raw words (79803 effective words) took 0.1s, 650190 effective words/s\n",
      "2019-04-23 11:42:49,757 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-23 11:42:49,760 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-23 11:42:49,762 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-23 11:42:49,765 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 11:42:49,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 11:42:49,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 11:42:49,783 : INFO : EPOCH - 5 : training on 129923 raw words (79708 effective words) took 0.1s, 691070 effective words/s\n",
      "2019-04-23 11:42:49,783 : INFO : training on a 649615 raw words (398634 effective words) took 0.6s, 651199 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 845 word vectors\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, train_seq, val_seq, y_train, y_val = preprocess(dataset='vqa', \n",
    "                                                                  n_classes=2, \n",
    "                                                                  verbose=False, \n",
    "                                                                  pretrained_embedding=False)\n",
    "val_data = (val_seq, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file: ./LSTM/0.001_1e-07_32_500.log\n",
      "Train on 3230 samples, validate on 513 samples\n",
      "Epoch 1/500\n",
      "3230/3230 [==============================] - 17s 5ms/step - loss: 0.7401 - acc: 0.5477 - val_loss: 0.6662 - val_acc: 0.6140\n",
      "Epoch 2/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6993 - acc: 0.6108 - val_loss: 0.7150 - val_acc: 0.5721\n",
      "Epoch 3/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6809 - acc: 0.6407 - val_loss: 0.6401 - val_acc: 0.7086\n",
      "Epoch 4/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6668 - acc: 0.6593 - val_loss: 0.6804 - val_acc: 0.6423\n",
      "Epoch 5/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6556 - acc: 0.6738 - val_loss: 0.7453 - val_acc: 0.3402\n",
      "Epoch 6/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6459 - acc: 0.6854 - val_loss: 0.6691 - val_acc: 0.7232\n",
      "Epoch 7/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6377 - acc: 0.6972 - val_loss: 0.5888 - val_acc: 0.6228\n",
      "Epoch 8/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6319 - acc: 0.6938 - val_loss: 0.5935 - val_acc: 0.6413\n",
      "Epoch 9/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6231 - acc: 0.7054 - val_loss: 0.6232 - val_acc: 0.7368\n",
      "Epoch 10/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6187 - acc: 0.7101 - val_loss: 0.6412 - val_acc: 0.7261\n",
      "Epoch 11/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6132 - acc: 0.7178 - val_loss: 0.5945 - val_acc: 0.7407\n",
      "Epoch 12/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.6059 - acc: 0.7277 - val_loss: 0.6066 - val_acc: 0.7388\n",
      "Epoch 13/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5989 - acc: 0.7266 - val_loss: 0.5916 - val_acc: 0.6559\n",
      "Epoch 14/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5950 - acc: 0.7289 - val_loss: 0.6038 - val_acc: 0.7398\n",
      "Epoch 15/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5940 - acc: 0.7339 - val_loss: 0.6092 - val_acc: 0.7368\n",
      "Epoch 16/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5879 - acc: 0.7331 - val_loss: 0.6034 - val_acc: 0.7407\n",
      "Epoch 17/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5851 - acc: 0.7385 - val_loss: 0.6368 - val_acc: 0.6472\n",
      "Epoch 18/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5810 - acc: 0.7407 - val_loss: 0.6042 - val_acc: 0.7368\n",
      "Epoch 19/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5770 - acc: 0.7407 - val_loss: 0.6169 - val_acc: 0.7320\n",
      "Epoch 20/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5778 - acc: 0.7396 - val_loss: 0.5889 - val_acc: 0.7407\n",
      "Epoch 21/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5732 - acc: 0.7488 - val_loss: 0.5870 - val_acc: 0.7427\n",
      "Epoch 22/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5712 - acc: 0.7460 - val_loss: 0.5849 - val_acc: 0.7495\n",
      "Epoch 23/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5706 - acc: 0.7477 - val_loss: 0.5696 - val_acc: 0.7495\n",
      "Epoch 24/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5660 - acc: 0.7522 - val_loss: 0.5907 - val_acc: 0.6423\n",
      "Epoch 25/500\n",
      "3230/3230 [==============================] - 11s 3ms/step - loss: 0.5652 - acc: 0.7505 - val_loss: 0.5813 - val_acc: 0.7485\n",
      "Epoch 26/500\n",
      "2336/3230 [====================>.........] - ETA: 2s - loss: 0.5610 - acc: 0.7545"
     ]
    }
   ],
   "source": [
    "L = 1e-3\n",
    "R = 1e-7\n",
    "B = 32\n",
    "E = 500\n",
    "model, history = skill_predictor(train_seq, embedding_matrix,\n",
    "                 train_labels=y_train,\n",
    "                 val_data=(val_seq,y_val),\n",
    "                 learning_rate=L,\n",
    "                 lstm_dim=100,\n",
    "                 batch_size=B,\n",
    "                 num_epochs=E,\n",
    "                 optimizer_param=SGD(lr=L, nesterov=True),\n",
    "                 n_classes=2,\n",
    "                 regularization=R, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_seq, verbose=0)\n",
    "y_pred_text = [1 if i >= 0.5 else 0 for i in preds[:,0]]\n",
    "y_pred_color = [1 if i >= 0.5 else 0 for i in preds[:,1]]\n",
    "print(\"VizWiz, all features - accuracy\\ntext: {}\\ncolor:{}\".format(accuracy_score(y_val[:,0], y_pred_text),\n",
    "                                                        accuracy_score(y_val[:,1], y_pred_color)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
